# 머신러닝 기초 (지도학습 - 분류)

> 🗓️ **2025-11-04**  
> ✍🏼 **작성자 : unz**

## 📝 목차

1. 분류(Classification)란?
2. 선형 회귀로 분류를 시도할 떄의 문제점
3. 로지스틱 회귀(Logistic Regression)
4. MLE(Maximum Likelihood Estimation)
5. 손실 함수(Loss Function)
6. 분류 평가 지표
7. ROC-AUC

---

## 1. 분류(Classification)란?

> 학습 데이터의 feature와 label을 이용하여 새로운 데이터가 어떤 범주에 속할지 예측하는 것

### 1-1. 이진 분류(Binary Classification)

> target 값이 두 가지 중 하나인 경우 두 개의 클래스 중 하나를 선택

- 양성 / 음성
- 스팸 / 정상
- 강아지 / 고양이

### 1-2. 다중 분류(Multi-class Classification)

> target 값이 세 개 이상의 범주로 구성된 경우 여러 개의 클래스 중 확률이 높은 하나를 선택

- 붓꽃(Iris) 품종 분류(Setosa / Versicolor / Virginica)
- 손글씨 숫자 인식(0, 1, 2, ... 9)

## 2. 선형 회귀로 분류를 시도할 떄의 문제점

> 왜 분류 문제에 선형 회귀($y = wx + b$)를 그대로 사용하면 안 될까?

- 선형 회귀는 결과값 $y$가 $-\infty$에서 $+\infty$까지 나올 수 있다.
- 하지만 분류에서 확률은 반드시 0 과 1 사이여야 한다.
- 데이터 세트에 아주 큰 값이 하나만 섞여도 회귀선이 크게 왜곡되어 결정 경계가 무너진다.
- 범주 간에 순서가 없는 경우에도 선형 회귀는 숫자의 크기 차이로 데이터를 해석하는 오류가 발생할 수 있다.

## 3. 로지스틱 회귀(Logistic Regression)

- 선형 회귀의 결과를 시그모이드 함수에 통과시켜 0 과 1 사이의 값으로 변환한다.
- 임계값 0.5를 기준으로 0.5 이상은 1, 미만은 0으로 분류
- 임계값(Threshold)을 보통 0.5를 기준으로 삼지만 상황에 따라 조정 가능
  - 암 진단 : 0.3으로 낮춰서 놓치지 않기
  - 스팸 필터 : 0.7로 높여서 오판 줄이기

### 3-1. 시그모이드 함수(Sigmoid Function)

- 시그모이드 함수는 선형 회귀의 출력값($z$)을 0 과 1 사이의 확률값으로 압축한다.
- 수식 : $f(x) = \frac{1}{1 + e^{-x}}$
- $z$가 매우 크면 $1$에 수렴
- $z$가 매우 작으면 $0$에 수렴
- $z=0$일 때 함숫값은 $0.5$

### 3-2. 결정 경계(Decision Boundary)

> 모델이 특정 클래스로 분류하는 기준이 되는 선

- 로지스틱 회귀에서는 시그모이드 결과값이 0.5 이상이면 1, 미만이면 0으로 판단
- 즉, $w^Tx + b = 0$이 되는 지점이 결정 경계가 된다.

## 4. MLE(Maximum Likelihood Estimation)

> 관측된 데이터가 발생할 확률을 최대화하는 파라미터를 찾는 방법

- 로지스틱 회귀에서는 최소제곱법(MSE)을 쓰면 손실 함수가 비볼록 형태가 되어 로컬 미니멈에 빠질 위험이 크다.
- 따라서 MLE를 사용하여 가중치를 최적화한다.
- 이 데이터가 나타날 확률을 최대화 하는 $w$, $b$ 찾기

## 5. 손실 함수(Loss Function)

> 모델의 예측값과 실제값의 차이(오차)를 계산하는 함수  
> 분류 문제에서는 확률 분포의 차이를 계산하는 Cross Entropy가 주로 사용된다.

### 5-1. 이진 크로스 엔트로피 (BCE, Binary Cross Entropy)

> 이진 분류 문제에서 사용되는 손실 함수  
> 모델이 출력한 확률값이 실제 정답에 가까울수록 손실은 0에 수렴하고, 멀어질수록 손실은 기하급수적으로 커진다.

### 5-2. 카테고리컬 크로스 엔트로피 (CCE, Categorical Cross Entropy)

> 다중 분류 문제에서 사용되는 손실 함수  
> 각 클래스에 대한 확률 분포를 비교한다.

## 6. 분류 평가 지표

|                        |                                                       |                                                   |
| ---------------------- | ----------------------------------------------------- | ------------------------------------------------- |
| **정확도 (Accuracy)**  | 전체 데이터 중 맞게 예측한 비율                       | $\frac{TP+TN}{TP+TN+FP+FN}$                       |
| **정밀도 (Precision)** | 모델이 Positive라고 예측한 것 중 실제 Positive인 비율 | $\frac{TP}{TP+FP}$                                |
| **재현율 (Recall)**    | 실제 Positive인 것 중 모델이 Positive라고 맞춘 비율   | $\frac{TP}{TP+FN}$                                |
| **F1-Score**           | 정밀도와 재현율의 조화 평균                           | $2*\frac{Precision * Recall}{Precision + Recall}$ |

## 7. ROC-AUC

### 7-1. ROC Curve

> 임계값(Threshold)을 변화시킴에 따라 모델의 TPR과 FPR이 어떻게 변하는지를 나타낸 곡선

- TPR (True Positive Rate, 재현율): 실제 Positive 중 Positive로 맞게 예측한 비율. ($TP / (TP + FN)$)
- FPR (False Positive Rate): 실제 Negative 중 Positive로 잘못 예측한 비율. ($FP / (FP + TN)$)
- 그래프의 X축은 FPR, Y축은 TPR
- 좋은 모델일수록 FPR이 낮은 상태에서 TPR이 빠르게 1에 도달하여, 곡선이 왼쪽 상단 모서리에 가깝게 위치한다.

### 7-2. AUC (Area Under Curve)

> ROC Curve 아래의 면적

- 값의 범위는 0.5 ~ 1 사이
- 1.0 : 완벽한 분류 모델
- 0.8 ~ 0.9 : 좋은 분류 모델
- 0.5 : 랜덤 추측 수준

### 7-3. ROC-AUC의 장점

- 특정 임계값 하나를 기준으로 평가하지 않고, 모든 가능한 임계값에서의 성능을 종합적으로 보여준다.
- 데이터 셋의 클래스 분포가 편향되어 있어도(예: 암 환자 1명, 정상 99명), 모델의 분류 능력을 객관적으로 측정할 수 있다.
